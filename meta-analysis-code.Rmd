---
title: "A meta-analytic review of the associations between cognitive appraisals and emotions in cognitive appraisal theory"
author: "Anonymous Authors"
output:
  html_document:
    theme: darkly
    highlight: tango
    df_print: paged
    code_folding: hide
  html_notebook:
    toc: yes
    toc_depth: '3'
fontsize: 16pt
runtime: shiny
---


This document includes an R Shiny application, which provides an interactive UI on which to query our data. In particular, we provide "interactive" versions of the large Tables in our paper, and you can click

To run this application locally, we recommend using RStudio. When you load this file in RStudio, it would prompt you to install any packages you need (including knitr, shiny, etc). Then you just hit "Run Document", it should launch!



```{r preamble, echo=T, message=F, warning=F}
# import libraries for meta-analysis
library(metaSEM)
library(mvmeta)
library(metafor)
library(tidyverse)
library(psych) # to convert z to r using fisherz2r(meta_df$b[1])
library(bslib)
library(pander)

my_theme <-  theme_bw() + theme(legend.position="top",
                                strip.background = element_rect(fill="#FFFFFF"), 
                                strip.text = element_text(size=12), 
                                axis.text = element_text(size=12),
                                axis.title.x = element_text(size=14, vjust=-0.2),
                                axis.title.y = element_text(size=14, vjust=0.8),
                                legend.text = element_text(size=12),
                                title = element_text(size=18, vjust=1),
                                panel.grid = element_blank())
```


```{r read-in-data-and-cleaning, echo=T, message=F, warning=F}
## -- This chunk reads in the data and defines the emotions/appraisals -- ##

data <- read.csv('meta-analysis_data.csv',header=T) %>% 
  filter(included=="yes") %>%
  droplevels() %>%
  mutate(Appraisal_Raw = Appraisal,
         Emotion_Raw = Emotion)

### --- Cleaning emotions and appraisals ---- ####

LIST_OF_EMOTIONS_Short = c("anger", "anxiety", "boredom", "enjoyment", "fear", 
                           "guilt", "joy", "pride", "sadness", "shame")
LIST_OF_EMOTIONS_Long = c(
  "admiration", "affection", "amusement", "apathy", "awe", 
  "bitter", "challenge", "comfortable", "compassion", "confident", 
  "confusion", "contempt", "contentment", "curious", "disappointment", 
  "disgust", "distrust", "embarrassment", "empathy", "enthusiasm", 
  "envy", "excitement", "frustration", "gladness", "gratitude", 
  "homesickness", "hope", "inspiration", "interest", "irritation", 
  "jealousy", "loneliness", "longing", "love", "nostalgia", 
  "pity", "playfulness", "pleasure", "psyched-up", "regret", 
  "relief", "resignation", "schadenfreude", "self-anger", "self-pity", 
  "serenity", "surprise", "sympathy", "tenderness", "unfriendly", 
  "unlucky", "worry")


# some studies measured multiple appraisals within the same "cluster" (that we define).
# for these, we picked the most relevant one and excluded the rest.

LIST_OF_APPRAISALS = c(
  'accountability-circumstances', 'accountability-other', 
  'accountability-self', 'attainability', 'attentional activity', 
  'certainty', 'challenge', 'closeness', 'concern for others', 
  'control-circumstances', "control-other", "control-self", 
  'desire for object', 'difficulty', "easing of threat", 
  'effort', 'effortful success', 'emotion-focused coping potential', 
  "evil character", "expected success", 'expectedness', 
  'fairness', 'future expectancy', 'globality', 'goal conduciveness', 
  'goal relevance', 'harm', 'helplessness', 'intentionality', "liking", 
  'loss', "modifiability", "negative likelihood",
  'normative significance (external)', 'normative significance (internal)', 
  'novelty',  'other-involved', 'perceived obstacle', 'pleasantness', 
  'predictability', 'problem-focused coping potential', "reality", 
  "remarkable", "safety", "self-esteem decreased", 'severity', 'stability', 
  'temporal distance', 'threat', 'uniqueness', 'urgency', 'value')
     

# The following lines "groups" appraisals with different terminologies 
# into the appraisal "clusters" we have defined in the paper, i.e., 
# LIST_OF_APPRAISALS just above. 
data <- data %>%
  mutate(Appraisal = fct_collapse(Appraisal,
    'accountability-circumstances' = c("agency-circumstances",
                                       'circumstances-attribution', 
                                       'situational-agency',
                                       "situation-attribution"),
    'accountability-other' = c('agency-other', 'external agency',
                               'other-accountability',
                               'other-attribution', 'other-blame',
                               'other-caused',
                               'other-responsibility'),
    'accountability-self' = c("agency-self", 'internal agency', 
                              "internal attribution", "internal locus",
                              'self-accountability', 'self-attribution',
                              'self-blame', 'self-caused', 
                              'self-responsibility'),
    'attainability' = c('attainability', "possibility"),
    'attentional activity' = c('attention', 'attentional activity', 
                               'consideration'),
    'certainty' = c('certainty', 'clarity', 'understandability'),
    'challenge' = c('challenge'),
    'closeness' = c('closeness'),
    'concern for others' = c('other-concern'),
    'control-circumstances' = c("circumstances-control", 'situational-control'),
    "control-other" = c( "control-other", 'external control'),
    "control-self" = c('control-self', 'personal control', 'power'),
    'desire for object' = c('desirability'),
    'difficulty' = c('difficulty', 'situational demand'),
    "easing of threat" = c("easing of threat"),
    'effort' = c('effort'),
    'effortful success' = c('effortful optimism', "potential for success"),
    'emotion-focused coping potential' = c('emotion-focused coping potential'),
    "evil character" = c('evil character'),
    "expected success" = c("expected success"),
    'expectedness' = c('expectation', 'expectedness'),
    'fairness' = c("deservingness", "fairness" ,'injustice (reversed)', 
                   "justice", 'legitimacy', 'unfairness (reversed)'),
    'future expectancy' = c("future expectancy", 
                            "future expectations", "positive future expectancy", 
                            "negative future expectancy",
                            "outcome expectancy", "optimism"),
    'globality' = c('globality'),
    'goal conduciveness' = c('benefit',  
                             'goal conduciveness',
                             'goal congruence', 
                             'goal hindrance (reversed)', 'motivational congruence',
                             "motivational consistency",
                             'situational state'),
    'goal relevance' = c('centrality', 'goal relevance',
                         'importance',
                         'motivational relevance', "self-concern"),
    'harm' = c('harm'),
    'helplessness' = c('helplessness'),
    'intentionality' = c('other-intentionality', 'intentionality'), 
    "liking" = c("liking"),
    'loss' = c('loss', 'reversibility (reversed)'),
    "modifiability" = c("modifiability"),
    "negative likelihood" = c("negative likelihood"),
    'normative significance (external)' = 
      c('external self-compatibility', 'fail to live up to external standards (reversed)',
        "immorality (reversed)",
        'norm compatibility', 'norm violation (reversed)'),
    'normative significance (internal)' = 
      c("compatibility with individual norms", "compatibility with internal standards",
        "internal self-compatibility", "moral congruence", "self-consistency"),
    'novelty' = c('novelty', "familiarity (reversed)"), 
    'other-involved' = c('other-involved'),
    'perceived obstacle' = c('obstacle','problems'),
    'pleasantness' = c('intrinsic pleasantness', 'pleasantness', 'valence'),
    'predictability' = c('predictability', "outcome probability"),
    'problem-focused coping potential' = c('competence','coping potential', 'problem-focused coping potential', 'self-efficacy'),
    "reality"  = c("reality"),
    "remarkable" = c('remarkable'),
    "safety" = c("safety"),
    "self-esteem decreased" = c("self-esteem decreased"),
    'severity' = c("impact", "severity"),
    'stability' = c('stability'),
    'temporal distance' = c('temporal distance'),
    'threat' = c('threat', 'danger', 'risk', "susceptibility"),
    'uniqueness' = c('uniqueness', 'pattern/unique'),
    'urgency' = c('urgency'),
    'value' = c('attainment value', 'intrinsic value', 'outcome value','value') 
  )) %>% mutate(Appraisal = fct_relevel(Appraisal, LIST_OF_APPRAISALS),
                Emotion = factor(Emotion))



## The rows with the following emotions are not included in meta-analysis 
##   (reasons are given in the remarks column)
## These emotions are already tagged with "no" in the `included` column
##   and so are already excluded by the above data read-in.
# LIST_OF_EMOTIONS_NOTUSED = c("depression", "stress", "beloved", "embrace", 
#                              "grief", "hate", "hostility", "melancholy", "rage")

## similarly the following appraisals are not included. 
# LIST_OF_APPRAISALS_NOTUSED = 
#   c("ability", # consists of multiple appraisals, stable and uncontrollable
#     "causal locus", # this study also measured 'other-accountability', which is
#                     # more relevant
#     "coping ability", # this study measured on a nominal scale; 
#                       # each level had a different anchor point
#     "external causation", # one study measured on nominal scale
#                           # another study included 'other person' and 'external'
#                           # and one study used factor scores
#     "external locus", # for this study, unclear whether 'other person' or 'external'
#     "extrinsic value", # this study had both 'intrinsic' and 'extrinsic'
#                        # we chose to use intrinsic
#     "locus of causality", # unclear whether 'other person' or 'external'
#     "obstacle/effort", # consists of multiple appraisals
#     'other-significance', # excluded because this study also has 'other-concern'
#     "uncontrollable", # unclear in the study's definition.
#     "valued achievement", # multiple appraisals: "accountability-self", 
#                          # and "goal conduciveness"
#     "other-caused failure", "other-caused success",
#     "self-caused failure", "self-caused success")

```








```{r helper-functions, echo=T, eval=T}

## --- This chunk contains helper-functions to compute the meta-analysis, 
## publication bias analyses, and other functions for creating the tables. 
## -- ##


# P-curve analysis
# The following are the auxiliary and main functions used to run 
# the p-curve analysis. I adapted the code from the original authors -
# http://p-curve.com/app4/pcurve_app4.06.r

# Function 1 - functions that find non-centrality parameter for f,chi 
#    distributions that gives some level of power
# F-test 
# Note: starting with app 4.0, t() are converted to F() and Z to chisq() to 
#      avoid unnecessary repetition of code
# So we only need code to find ncp for F() and chisq()
getncp.f = function(df1,df2, power)   {      
  error = function(ncp_est, power, x, df1,df2) 
    pf(x, df1 = df1, df2=df2, ncp = ncp_est) - (1-power)   
  xc=qf(p=.95, df1=df1,df2=df2) 
  return(uniroot(error, c(0, 1000), x = xc, df1 = df1,df2=df2, power=power)$root)  
}

# chisq-test
getncp.c =function(df, power)   {      
  xc=qchisq(p=.95, df=df) 
  error = function(ncp_est, power, x, df) 
    pchisq(x, df = df, ncp = ncp_est) - (1-power)   
  return(uniroot(error, c(0, 1000), x = xc, df = df, power=power)$root)   
}

# Combine both in single function
getncp = function(family,df1,df2,power) {
  if (family=="f") ncp=getncp.f(df1=df1,df2=df2,power=power)
  if (family=="c") ncp=getncp.c(df=df1,power=power)
  return(ncp)  
}

# Function 3 - pbound: bound p-values and pp-values by precision of 
#                     measurement to avoid errors
pbound=function(p) pmin(pmax(p,2.2e-16),1-2.2e-16)

# Function 4 - prop33(pc) - Computes % of p-values that are expected to be 
#                           smaller than pc, for the tests submitted to 
#                           p-curve, if power is 33%
prop33=function(pc, family1, p, r_df, ncp33)
{
  #pc: critical  p-value
  #Overview:
  #Creates a vector of the same length as the number of tests 
  #        submitted to p-curve, significant and not,
  #    and computes the proportion of p-values expected to be smaller than 
  #        {pc} given the d.f. 
  #    and outputs the entire vector, with NA values where needed
  # F-tests (& thus  t-tests)
  prop=ifelse(family1=="f" & p<.05,
              1-pf(qf(1-pc,df1=1, df2=r_df),df1=1, df2=r_df, ncp=ncp33),NA)
  # Chi2 (& thus Normal)
  prop=ifelse(family1=="c" & p<.05,
              1-pchisq(qchisq(1-pc,df=df1), df=df1, ncp=ncp33),prop)
  # output it
  prop
}

# Function 5 Stouffer test for a vector of pp-values
stouffer=function(pp) sum(qnorm(pp),na.rm=TRUE)/sqrt(sum(!is.na(pp)))

# main p-curve function. This function takes in a dataframe 
#          (that has already been subsetted by the appraisal and emotion) 
#          and computes the necessary p-curve statistics
p_curve = function(df) {
  r_values <- df$r
  r_df = df$N - 2
  # Create family to turn t-->F
  family1 = rep("f",dim(df)[1])
  #For correlation, first turn value (r) to t, then square t. 
  #     (using t=r/sqrt(1-r**2)/DF)
  value= (r_values/(sqrt((1-r_values**2)/r_df)))**2
  # Compute p-values
  p = 1-pf(value,df1=1,df2=r_df)
  p=pbound(p) 
  # Count  studies
  ksig= sum(p<.05,na.rm=TRUE)     #significant studies
  khalf=sum(p<.025,na.rm=TRUE)  #half p-curve studies
  
  # COMPUTE PP-values
  #2.1 Right Skew, Full p-curve
  ppr=as.numeric(ifelse(p<.05,20*p,NA))            
  #If p<.05, ppr is 1/alpha*p-value, so 20*pvalue, otherwise missing. 
  ppr=pbound(ppr)      #apply pbound function to avoid 0
  
  #2.2 Right Skew, half p-curve
  ppr.half=as.numeric(ifelse(p<.025,40*p,NA))    
  #If p<.05, ppr is 40*pvalue, otherwise missing. 
  ppr.half=pbound(ppr.half)
  
  #2.3 Power of 33%
  #2.3.1 NCP for  f,c distributions
  # NCP33 (noncentrality parameter giving each test 
  #    in p-curve 33% power given the d.f. of the test)
  ncp33=mapply(getncp,df1=1,df2=r_df,power=1/3,family=family1) 
  #See function 1 above
  
  #2.3.2 Full-p-curve
  #Using the ncp33 compute pp33
  pp33=ifelse(family1=="f" & p<.05,3*(pf(value, df1=1, df2=r_df, ncp=ncp33)-2/3),NA)
  pp33=pbound(pp33)
  
  #2.3.3 HALF-p-curve
  #Share of p-values expected to be p<.025 if 33% power 
  #   (using Function 4 from above, prop33() )
  prop25=3*prop33(.025, family1 = family1, p = p, r_df = r_df, ncp33 = ncp33 )
  prop25.sig=prop25[p<.05]
  
  #Compute pp-values for the half
  pp33.half=ifelse(family1=="f" & p<.025, (1/prop25)*(
    pf(value,df1=1,df2=r_df,ncp=ncp33)-(1-prop25)),NA)
  pp33.half=pbound(pp33.half)
  
  #########################################################################  
  # INFERENCE - STOUFFER & BINOMIAL
  ###########################################################################  
  
  # Convert pp-values to Z scores, using Stouffer function above
  Zppr =     stouffer(ppr)            #right skew  - 
                                      # this is a Z value from Stouffer's test
  Zpp33=     stouffer(pp33)           #33% - idem 
  Zppr.half= stouffer(ppr.half)       #right skew, half p-curve - idem 
  Zpp33.half=stouffer(pp33.half)      #33% skew, half p-curve - idem 
  
  # Overall p-values from Stouffer test
  p.Zppr =pnorm(Zppr)	
  p.Zpp33=pnorm(Zpp33)
  p.Zppr.half =pnorm(Zppr.half)
  p.Zpp33.half=pnorm(Zpp33.half)
  
  return(c(Zppr, p.Zppr, Zpp33, p.Zpp33, Zppr.half, p.Zppr.half))
}




### the following functions help to provide the interpretation
### of significant appraisal-emotion relationships

# These mappings just make the interpretation sound more grammatical.
emotion_strings = data.frame(
  emotion = c(LIST_OF_EMOTIONS_Short, LIST_OF_EMOTIONS_Long),
  string = c(LIST_OF_EMOTIONS_Short, 
    c("admiration", "affection", "amusement", "apathy", "awe", 
      "bitter", "challenge", "comfortable", "compassion", "confidence", 
      "confusion", "contempt", "contentment", "curiosity", "disappointment", 
      "disgust", 
      "distrust", "embarrassment", "empathy", "enthusiasm", "envy", 
      "excitement", "frustration", "gladness", "gratitude", "homesickness", 
      "hope", "inspiration", "interest", "irritation", "jealousy", 
      "feelings of loneliness", 
      "feelings of longing", 
      "love", "nostalgia", "pity", "playfulness", 
      "pleasure", "psyched-up", "regret", "relief", "resignation",  
      "feelings of schadenfreude", 
      "self-anger", "self-pity", "serenity", "surprise", 
      "sympathy", "tenderness", 
      "feelings of unfriendliness", 
      "feelings of unluckiness", "worry"))
)
appraisal_strings = data.frame(
  appraisal = LIST_OF_APPRAISALS,
  string = c(
  'attribution of the cause of the situation to impersonal circumstances', 
  'perceived responsibility for the cause of the situation attributed to other people/objects', 
  'perceived personal responsibility of the cause of the situation', 
  'perception that one could obtain what one desires', 
  'perceived need to take time/effort to attend to the situation further', 
  'understanding of the situation', 
  'perception of a future gain after overcoming an obstacle in the situation', 
  'perception of closeness of the relationship to another person', 
  "concern for others' well-being in the situation", 
  'perception that impersonal circumstances have control over the situation', 
  "perception that other people/objects have control over the situation", 
  "perceived control over the situation", 
  'desire for something another person has', 
  'perceived difficulty', 
  "perception that a threat or harm has been removed from the situation", 
  'need to exert effort to deal with the situation', 
  'perception that effort could make the situation better', 
  'ability to emotionally cope and adapt to the situation', 
  "perception of others as dispositionally evil", 
  "expectation to achieve one's goals", 
  'expectation of the occurrence of the situation', 
  'perceived fairness of the situation', 
  'expectation that the situation will get better', 
  "perception that the event is relevant to all aspect of one's life", 
  "consistency of the situation with one's goals", 
  "perceived relevance of the situation to one's goals", 
  'perceived harm', 
  'perceived inability to improve the situation', 
  'perceived intentionality of the cause of the event either by oneself or others', 
  "liking for another person", 
  'perception that something irretrievable has been lost', 
  "perception that the situation could be modified", 
  "perceived likelihood of each possible negative outcome occurring",
  'consistency of the situation with external and social norms',
  "consistency of the situation with one's ideals", 
  'perceived novelty in the situation',  
  "perception that another's well-being is involved", 
  'perception that an obstacle hampers the attainment of a desired goal', 
  'perceived pleasantness of the situation', 
  'ability to predict what is going to occur in the future', 
  'perceived ability to cope and adapt to the situation', 
  "perception that is situation is real and had already occurred", 
  "feeling that it was remarkable to have gotten this outcome", 
  "perception that there is nothing is to be concerned about or needs to be done", 
  "perception that one's self-esteem has decreased", 
  "perceived severity of the consequences of the situation to one's well-being", 
  'perception that the situation is stable and permanent', 
  'perceived temporal distance to a remembered past situation', 
  'perceived imminent threat in the situation', 
  'perception of how unique the situation was', 
  'need to immediately attend to the situation', 
  "perceived value of the situation to one's goals and desires")
)

# function that returns a grammatical string for the table
return_interpretation = function(this_appraisal, this_emotion, r) {
  # Example interpretation:
  # The greater the 
  # perceived responsibility for the cause of the 
  #     situation attributed to other people/objects
  # , the 
  # greater 
  # the 
  # anger
  
  appraisal_string = appraisal_strings[
    appraisal_strings$appraisal==this_appraisal, "string"]
  emotion_string = emotion_strings[
    emotion_strings$emotion==this_emotion, "string"]
  if(r>0) {comparator = "greater"} else {comparator = "less"}
  
  interpretation_string = paste(
    "The greater the ", 
    appraisal_string, 
    ", the ", comparator, " the ",
    emotion_string, ".", sep=""
  )
  return(interpretation_string)
}

```





```{r make-table-function, echo=F, eval=T}

# This function is a helper function to construct Tables 3 and 6.
#   (Meta-analysis for a given Emotion and Appraisal)
#   It takes in the data frame and produces the necessary statistics
#   as a row of a data frame.
meta_analysis_for_table = function(df, this_emotion, 
                                   num_digits=4, 
                                   pubBias = TRUE, 
                                   interpretation=TRUE) {
  meta_df = rma(z,v,data=df, method = 'ML')
  
  if(meta_df$pval<0.001) {
    pstring = "***"
  } else if(meta_df$pval<0.01) {
    pstring = "**"
  } else if(meta_df$pval<0.05) {
    pstring = "*"
  } else { pstring = "" }
  
  table_df = data.frame(
      Emotion = this_emotion,
      Appraisal = df$Appraisal[1],
      k = nrow(df),
      # apply fisherz2r()
      r = paste(format(fisherz2r(meta_df$b[1]), digits=num_digits), 
                pstring, sep = ""))
  
  if(nrow(df)>1) {
    if(meta_df$QEp<0.001) {
      Q_pstring = "***"
    } else if(meta_df$QEp<0.01) {
      Q_pstring = "**"
    } else if(meta_df$QEp<0.05) {
      Q_pstring = "*"
    } else { Q_pstring = "" }
    
    table_df = table_df %>% mutate(
      # 95% CI; apply fisherz2r()
      ci = paste(format(fisherz2r(meta_df$ci.lb), digits=num_digits), 
                 format(fisherz2r(meta_df$ci.ub), digits=num_digits), sep=", "),
      # Q statistic, (Q df), Q_pstring
      Q = paste(format(meta_df$QE, digits=num_digits), " (", 
                format(nrow(df) - 1, digits=num_digits), ")", Q_pstring, sep=""),
      # sqrt(tau^2)
      #tau2 = format(meta_df$tau2, digits=num_digits),
      tau = format(sqrt(meta_df$tau2), digits=num_digits),
      # I2
      I2 = format(meta_df$I2, digits=num_digits))
  } else {
    table_df = table_df %>% mutate(ci = NA, Q = NA, tau = NA, I2 = NA)
  }
  
  
  # the publication bias analyses only done if 10 or more studies. 
  if(pubBias & nrow(df)>=10) {
    reg_test = regtest(meta_df, model='rma')
    fsn_orwin = fsn(yi=z, vi=v, data=df, type='Orwin', target=0.05)  
    p_curve_results = p_curve(df)
    # p-curve significance
    # z_half
      if(p_curve_results[6]<0.001) { pstring1 = "***"
      } else if(p_curve_results[6]<0.01) { pstring1 = "**"
      } else if(p_curve_results[6]<0.05) { pstring1 = "*"
      } else { pstring1 = "" }
    
    # z_full
      if(p_curve_results[2]<0.001) { pstring2 = "***"
      } else if(p_curve_results[2]<0.01) { pstring2 = "**"
      } else if(p_curve_results[2]<0.05) { pstring2 = "*"
      } else { pstring2 = "" }
    
    # z_flat
      if(p_curve_results[4]<0.001) { pstring3 = "***"
      } else if(p_curve_results[4]<0.01) { pstring3 = "**"
      } else if(p_curve_results[4]<0.05) { pstring3 = "*" 
      } else { pstring3 = "" }
    
    
    table_df <- table_df %>% mutate(
      # Egger regression p value
      p_egger = format(reg_test$pval, digits=num_digits),
      # fail-safe N
      FSN = format(fsn_orwin$fsnum, digits=num_digits),
      # z_half
      z_half = paste(format(p_curve_results[5], digits=num_digits), 
                pstring1, sep = ""),
      # z_full
      z_full = paste(format(p_curve_results[1], digits=num_digits), 
                pstring2, sep = ""),
      # z_flat
      z_flat = paste(format(p_curve_results[3], digits=num_digits), 
                pstring3, sep = ""),
    )
  } else if (pubBias) { # 9 or fewer studies but still want to print pubBias
    table_df <- table_df %>% mutate(
      p_egger = NA, FSN = NA, z_half = NA, z_full = NA, z_flat = NA
    )
  }
  if(interpretation) {
    if(meta_df$pval<0.05) {
      table_df <- table_df %>% mutate(interpretation = 
        return_interpretation(df$Appraisal[1], this_emotion, fisherz2r(meta_df$b[1]))
        )
    } else {
      table_df <- table_df %>% mutate(interpretation = NA)
    }
  }
  
  return(table_df)
}




```

## Table for emotions with higher evidence (Table 3 in paper)

```{r shiny-app-appraisal-table-high_evidence_emotions, echo=FALSE}
shinyApp(

  ui = fluidPage(
    #theme = bs_theme(bootswatch = "darkly"),
    # App title ----
    titlePanel("Results of main analyses and publication bias analyses for emotions with high evidence (max k >=10)"),
    
    fluidRow(
      column(12,
             h3("Emotions in this table: Anger, Anxiety, Boredom, Enjoyment, Fear, Guilt, Joy, Pride, Sadness, Shame."),
      )
    ),
    
    fluidRow(
      column(3,
             selectInput("this_emotion", "Emotion",
                         choices = LIST_OF_EMOTIONS_Short)
      ),
      
      column(3,
             selectInput("this_appraisal", "Appraisal",
                         choices = c("All Appraisals", LIST_OF_APPRAISALS))
      ),
      
      column(6,
             c("Table Display Options"),
             checkboxInput("show_pub_bias", 
                           "Show Publication Bias Results", 
                           value = FALSE),
             checkboxInput("show_interp", 
                           "Show interpretation (for significant results)", 
                           value = TRUE)
             )
    ),
    
    fluidRow(
      column(12,
             dataTableOutput("table")
      )
    )
  ),
  
  server = function(input, output) {
    output$table = renderDataTable({
      this_table = data.frame()
      if(input$this_appraisal == "All Appraisals") { # looping through All appraisals
        for(this_appraisal in c(LIST_OF_APPRAISALS)) {
          df = data %>% filter(Emotion == input$this_emotion,
                               Appraisal == this_appraisal)
          if(nrow(df)>=1) {
            this_table = bind_rows(this_table, 
              meta_analysis_for_table(df, input$this_emotion,
                  pubBias=input$show_pub_bias,
                  interpretation=input$show_interp))
          }
        }
        this_table <- this_table %>% arrange(Emotion, desc(k), Appraisal) %>%
          rename(`Num Studies k` = k,
                 `Effect Size (Pearson r)` = r,
                 `95% Confidence Interval` = ci)
      } else { # only for the given appraisal
        df = data %>% filter(Emotion == input$this_emotion,
                             Appraisal == input$this_appraisal)
        if(nrow(df)>=1) {
          this_table = meta_analysis_for_table(df, input$this_emotion,
                              pubBias=input$show_pub_bias,
                              interpretation=input$show_interp) %>%
          rename(`Num Studies k` = k,
                 `Effect Size (Pearson r)` = r,
                 `95% Confidence Interval` = ci)
        } else {
          this_table = data.frame(Output="appraisal not found")
        }
      }
    })
    
  },

  options = list(height = 800)
)
```

Note: k denotes number of studies, r denotes the mean effect size in Pearson correlation coefficient, 95% CI denotes the 95% confidence interval of the mean effect size, τ denotes the true between-studies variability, I2 denotes the ratio of true between-study heterogeneity to total variance observed, df refers to the degrees of freedom, pe denotes the p-value of the Egger Regression Test, FSN denotes the Orwin’s fail-safe N, Zhalf denotes the Z statistic for the right skewness of the half p-curve, Zfull denotes the Z statistic for the right skewness of the full p-curve, Zflat denotes the Z statistic for the test of whether the observed full p-curve is significantly flatter than that of a 33%-power p-curve. The “Predictions & Findings” columns denotes whether the results were consistent with what previous literature has hypothesized; see text for description of categories. Within each emotion, the appraisals are sorted by k, then by alphabetical order. * p < .05; ** p < .01; *** p < .001


## Table for remainder of emotions

```{r shiny-app-appraisal-table-low_evidence_emotions, echo=FALSE}
shinyApp(

  ui = fluidPage(
    # App title ----
    titlePanel("Results of main analyses for emotions with less evidence (max k<10)."),
    
    fluidRow(
      column(3,
             selectInput("this_emotion", "Emotion",
                         choices = LIST_OF_EMOTIONS_Long)
      ),
      
      column(3,
             selectInput("this_appraisal", "Appraisal",
                         choices = c("All Appraisals", LIST_OF_APPRAISALS))
      ),
      column(6,
             c("Table Display Options"),
             checkboxInput("show_interp", 
                           "Show interpretation (for significant results)", 
                           value = TRUE)
             )
    ),
    
    fluidRow(
      column(12,
             dataTableOutput("table")
      )
    )
  ),
  
  server = function(input, output) {
    
    output$table = renderDataTable({
      this_table = data.frame()
      if(input$this_appraisal == "All Appraisals") { # looping through All appraisals
        for(this_appraisal in c(LIST_OF_APPRAISALS)) {
          df = data %>% filter(Emotion == input$this_emotion,
                               Appraisal == this_appraisal)
          if(nrow(df)>=1) {
            this_table = bind_rows(this_table, 
                               meta_analysis_for_table(df, input$this_emotion,
                                                       pubBias=FALSE,
                                                       interpretation=input$show_interp))
          }
        }
        this_table <- this_table %>% arrange(Emotion, desc(k), Appraisal) %>%
          rename(`Num Studies k` = k,
                 `Effect Size (Pearson r)` = r,
                 `95% Confidence Interval` = ci)
      } else { # only for the given appraisal
        df = data %>% filter(Emotion == input$this_emotion,
                             Appraisal == input$this_appraisal)
        if(nrow(df)>=1) {
          this_table = meta_analysis_for_table(df, input$this_emotion,
                                               pubBias=FALSE,
                                               interpretation=input$show_interp) %>%
          rename(`Num Studies k` = k,
                 `Effect Size (Pearson r)` = r,
                 `95% Confidence Interval` = ci)
        } else {
          this_table = data.frame(Output="appraisal not found")
        }
      }
    })
    
  },

  options = list(height = 500)
)
```



## Reference Look Up


```{r shiny-app-looking-up-refernces, echo=FALSE}
shinyApp(

  ui = fluidPage(
    # App title ----
    titlePanel("Use this app to lookup specific references"),
    
    fluidRow(
      column(6,
             selectInput("this_emotion", "Emotion",
                         choices = c(LIST_OF_EMOTIONS_Short, LIST_OF_EMOTIONS_Long))
      ),
      
      column(6,
             selectInput("this_appraisal", "Appraisal",
                         choices = c(LIST_OF_APPRAISALS))
      )
    ),
    
    fluidRow(
      column(12,
             dataTableOutput("table")
      )
    )
  ),
  
  server = function(input, output) {
    
    output$table = renderDataTable({
      this_table = data.frame()
        df = data %>% filter(Emotion == input$this_emotion,
                             Appraisal == input$this_appraisal)
        if(nrow(df)>=1) {
          this_table = df %>% 
            select(Study, Year, Appraisal, Emotion, Dissertation, r, z, remarks) %>%
            arrange(Study, Year)
        } else {
          this_table = data.frame(Output="appraisal not found")
        }
    })
    
  },

  options = list(height = 500)
)
```





### Making static tables
These next chunks are to create the static tables and figures for the paper. 

```{r make-static-tables-for-paper, warning=F, eval=F, echo=F, eval=F}
## Set `eval=T` to run this chunk.
## This chunk is to create the static Tables 3 and 6 in the paper
## This is written to file, not output.


## This next set of code writes the whole Table 3 to a .csv file
full_table = data.frame()
for(this_emotion in LIST_OF_EMOTIONS_Short) {
  this_table = data.frame()
  
  for(this_appraisal in LIST_OF_APPRAISALS) {
    df = data %>% filter(Emotion == this_emotion,
                         Appraisal == this_appraisal)
    if(nrow(df)>=1) {
      this_table = bind_rows(this_table, 
                             meta_analysis_for_table(df, this_emotion,
                                                     pubBias=TRUE,
                                                     interpretation=TRUE))
    }
  }
  this_table <- this_table %>% arrange(Emotion, desc(k), Appraisal)
  full_table = bind_rows(full_table, this_table, data.frame(NA))
}

full_table <- full_table %>% 
  mutate(blank1=NA, .after = k) %>%
  mutate(blank2=NA, .after = I2)

write.csv(full_table, "table3-raw.csv", row.names=F, na="")



## And this is for Table 6 (variable names are re-used)
full_table = data.frame()
for(this_emotion in LIST_OF_EMOTIONS_Long) {
  this_table = data.frame()
  
  for(this_appraisal in LIST_OF_APPRAISALS) {
    df = data %>% filter(Emotion == this_emotion,
                         Appraisal == this_appraisal)
    if(nrow(df)>=1) {
      this_table = bind_rows(this_table, 
                             meta_analysis_for_table(df, this_emotion,
                                                     pubBias=FALSE,
                                                     interpretation=TRUE))
    }
  }
  this_table <- this_table %>% arrange(Emotion, desc(k), Appraisal)
  full_table = bind_rows(full_table, this_table, data.frame(NA))
}

full_table <- full_table %>% 
  mutate(blank1=NA, .after = k)

write.csv(full_table, "table6-raw.csv", row.names=F, na="")

```




```{r calculate-descriptives, echo=T, eval=T, message=F}
# This chunk calculates some descriptives: total number of studies, etc

num_total_effect_sizes = nrow(data)
num_total_studies = length(unique(data$Study.ID))

# this following line does some regex manipulation
# to collapse different samples within the same article
unique_articles = data %>% 
  group_by(Study.ID) %>%
  filter(row_number()==1) %>%
  ungroup() %>%
  select(Study.ID, Study, Year) %>%
  mutate(Article = str_replace_all(Study,
    c("(main study)" = "",
      "[Ss]tudy [1-9][a-z]*" = "",
      "experiment [1-9]" = "",
      ", in-group condition" = "",
      ", out-group condition" = "",
      "Hangzhou sample" = "", "Yangshuo sample" = "",
      "study1: second grade sample" = "", "study1: third grade sample" = "",
      "study2" = "", 
      "US sample" = "", "Korean sample" = "", "Japanese sample" = "",
      "female sample" = "", "male sample" = "", "women" = "", "men" = "",
      "phase 1" = "", "; accounting" = "", "; aerospace" = "",
      "- climate change sample" = "",
      "- climate influenza sample" = "",
      "adult sample" = "", "child sample" = "",
      "Grade [1-9] sample" = "", "Great Lakes study" = "",
      "Watershed study: flood risk path" = "",
      "Watershed study: environmetal health of river path" = "",
      "[.]1a" = "", "[.]1b" = "", "[.]2" = "",
      "[()]" = "", ":"="", ";"="", ","=""
      )),
  Article = str_trim(Article),
  Article = paste(Article, Year)
)

num_total_articles = length(unique(unique_articles$Article))

num_total_emotion_appraisal_relationships = nrow(data %>% group_by(Emotion, Appraisal) %>% summarize(num = n()))


num_total_emotions = length(levels(data$Emotion))
num_total_appraisals = length(levels(data$Appraisal))

```


### Table: Descriptive Statistics

  Category                                          Count
----------                                          -------
Total number of effect sizes                        `r num_total_effect_sizes`
Total number of emotion-appraisal relationships     `r num_total_emotion_appraisal_relationships`
Total number of studies                             `r num_total_studies`
Total number of articles                            `r num_total_articles`
Total number of emotions                            `r num_total_emotions`
Total number of appraisals                          `r num_total_appraisals`


### Table: Breakdown of results

```{r descriptives-2, warning=F, echo=T, eval=T}
d2 <- read.csv("predicted_relationships.csv") %>% mutate(
  appraisal = tolower(as.character(appraisal)),
  prediction = factor(prediction, levels=c(
    "Predicted & Supported", "Predicted & Not Significant",
    "Predicted & Opposite", "No prediction & Significant",
    "No prediction & Not Significant"
  ))
)

for(thisline in c(1:nrow(d2))) {
  temp_df = data %>% filter(Emotion == d2$emotion[thisline],
                            Appraisal == d2$appraisal[thisline])
  meta_df = rma(z,v,data=temp_df, method = 'ML')

  d2$r_precise[thisline] = fisherz2r(meta_df$b[1])
} 

d2 = d2 %>% mutate(
  r_abs = abs(r_precise),
  z = fisherz(r_abs)
)

descriptivesTable2 = d2 %>% group_by(prediction) %>% 
  summarize(count = n(), r_mean = mean(r_abs), r_sd = sd(r_abs)) %>%
  ungroup() %>% mutate(r_se = r_sd/sqrt(count))

pander(descriptivesTable2)
```


Testing if effect sizes in 'Predicted & Supported' are higher than in 'No Prediction & Significant': (note that we convert the pearson `r`'s to `z`'s and do a two-sample t-test.)

```{r t-test-and-figure, fig.height = 4, fig.width = 9, echo=T, eval=T}
d2 %>% 
  filter(prediction %in% c("Predicted & Supported", 
                           "No prediction & Significant")) %>%
  t.test(z ~ prediction, data=.)

d2 %>% ggplot(aes(x=r_abs, fill=prediction)) + 
  geom_density(alpha=.3) + xlab("(Absolute) Effect Size") + 
  ylab("Density") + my_theme +
  guides(fill=guide_legend(nrow=2,byrow=TRUE))
```



#### Fig 2: Bubble Plot of Effect Sizes

```{r read-in-table-data-for-plot, echo=F, eval=T, fig.width=7, fig.height=4}
table3 = read.csv('table3-raw.csv', header=T) %>% 
  select(-blank1, -blank2, -`NA.`) %>% 
  filter(Appraisal != "") %>%
  mutate(Emotion = factor(Emotion),
         r_significant = factor( grepl("[*]", r)*1.0 , 
                                 levels=c(1,0), labels=c("Yes", "No")),
         r = as.numeric(str_replace_all(r, c("[*]" = ""))))


table3 %>% ggplot() + 
  # geom_rect(xmin = -1.0, xmax = -0.25, ymin=0, ymax = 12,
  #           alpha=0.2, fill="#EEEEEE") +
  geom_rect(xmin = 0.25, xmax = 1.00, ymin=0, ymax = 12,
            alpha=0.2, fill="#EEEEEE") +
  geom_point(aes(y=Emotion, x=abs(r), size=k, shape=r_significant), alpha=0.5,
             position=position_jitter(height=0.25)) + 
  scale_x_continuous(breaks=c(-0.5, -0.25, 0, 0.25, 0.5)) +
  scale_y_discrete(limits = rev(levels(table3$Emotion))) +
  scale_shape_manual(values = c(5, 1), name="Significant") +
  scale_size_continuous(name="Number of studies") + 
  guides(shape = guide_legend(nrow = 2, byrow = T)) +
  guides(size = guide_legend(nrow = 5, byrow = T)) +
  xlab("Absolute value of the effect size (correlation coefficient r)") +
  my_theme + theme(legend.position = "right",
                   legend.title = element_text(size=12),
                   legend.text = element_text(size=10))
# 7 x 4

```


#### Table 5 (Primary & Supplementary appraisals)

```{r make-table-5, warning=F, message=F, echo=F, eval=T}

full_table = data.frame()
for(this_emotion in c(LIST_OF_EMOTIONS_Short, LIST_OF_EMOTIONS_Long)) {
  this_table = data.frame()
  
  for(this_appraisal in LIST_OF_APPRAISALS) {
    df = data %>% filter(Emotion == this_emotion,
                         Appraisal == this_appraisal)
    if(nrow(df)>=1) {
      this_table = bind_rows(this_table, 
                             meta_analysis_for_table(df, this_emotion,
                                                     pubBias=FALSE,
                                                     interpretation=FALSE))
    }
  }
  this_table <- this_table %>% arrange(Emotion, desc(k), Appraisal)
  full_table = bind_rows(full_table, this_table)
}

full_table <- full_table %>% mutate(
  significant = grepl("[*]", r),
  r_bare = abs(as.numeric(gsub("[*]", "", r)))
) %>% select(-ci, -Q, -tau, -I2)

table5_intermediate = full_table %>% filter(significant) %>% 
  mutate(primary = (r_bare > .25)) %>%
  group_by(Emotion, primary) %>% arrange(Appraisal) %>% summarize(
    list_appraisals = paste0(Appraisal, collapse=", ")
  ) %>% arrange(Emotion, desc(primary))

table5 = full_join(
 table5_intermediate %>% filter(primary) %>% select(-primary) %>% rename(Primary = list_appraisals),
 table5_intermediate %>% filter(!primary) %>% select(-primary) %>% rename(Supplementary = list_appraisals),
 id=Emotion
) %>% arrange(Emotion)
pander(table5, split.table = Inf)
```





